dRec <- read.csv(paste(project_root,"/data/processed/receivingNews_data.csv", sep=""))
project_root = getwd()
source(paste(project_root,"/scripts/src/utility/ReceivingNews_analysis_utility.R", sep=""))
dRec <- read.csv(paste(project_root,"/data/processed/receivingNews_data.csv", sep=""))
dRec = rename_variables(dRec)
etwd()
getwd()
here::here()
install.packages('rprojroot')
library('rp^rojroot')
library('rprojroot')
find_rstudio_root_file()
dRec <- read.csv(paste(project_root,"/data/processed/receivingNews_data.csv", sep=""))
project_root = find_rstudio_root_file()
dRec <- read.csv(paste(project_root,"/data/processed/receivingNews_data.csv", sep=""))
dRec = rename_variables(dRec)
dRec = mutate_values(dRec)
project_root = find_rstudio_root_file()
source(paste(project_root,"/scripts/src/utility/ReceivingNews_analysis_utility.R", sep=""))
dRec <- read.csv(paste(project_root,"/data/processed/receivingNews_data.csv", sep=""))
dRec = rename_variables(dRec)
dRec = mutate_values(dRec)
response_successes = array()
for (sub in unique(dRec$subject)){
response_successes[sub] = sum(dRec$success[dRec$subject==sub])
end
}
response_successes
dRec$subject
response_successes = array()
for (sub in unique(dRec$Subject)){
response_successes[sub] = sum(dRec$Success[dRec$Subject==sub])
end
}
response_successes
response_successes/48*100
response_successes/100*48
response_successes/48*100
r = rbinom(258, size=48, prob=0.5)/48*100
r
response_successes
response_successes/48*100
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memory and report the memory usage
list.of.packages <- c("MKinfer", "ggplot2", "plyr", "BayesFactor", "bayestestR",
"rprojroot")
{
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
}
project_root = find_rstudio_root_file()
knitr::opts_knit$set(root.dir = paste(project_root,"/documents/reports", sep=""))
load(paste("../../outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", sep=""))
load(paste(project_root, "outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", sep=""))
load(paste(project_root, "/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", sep=""))
paste(project_root, "/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", sep="")
load(paste(project_root, "/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", sep=""))
project_root
load("C:/Users/vguigon/Desktop/Research_directory/receivingNews/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData")
load("C:/Users/vguigon/Desktop/Research_directory/receivingNews/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData")
devtools::use_data("C:/Users/vguigon/Desktop/Research_directory/receivingNews/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", internal = TRUE)
require("devtools")
install.packages("devtools")
require("devtools")
devtools::use_data("C:/Users/vguigon/Desktop/Research_directory/receivingNews/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", internal = TRUE)
library("devtools")
devtools::use_data("C:/Users/vguigon/Desktop/Research_directory/receivingNews/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", internal = TRUE)
load("C:/Users/vguigon/Desktop/Research_directory/receivingNews/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData")
readRDS("C:/Users/vguigon/Desktop/Research_directory/receivingNews/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData")
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memory and report the memory usage
list.of.packages <- c("MKinfer", "ggplot2", "plyr", "BayesFactor", "bayestestR",
"rprojroot")
{
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
}
set.seed(12345)
project_root = find_rstudio_root_file()
source(paste(project_root,"/scripts/src/utility/ReceivingNews_analysis_utility.R", sep=""))
dRec <- read.csv(paste(project_root,"/data/processed/receivingNews_data.csv", sep=""))
dRec = rename_variables(dRec)
dRec = mutate_values(dRec)
N_TRIALS = 48
N_CONDS = 6
themes = c("Ecology", "Democracy", "SocJust")
conds_list = rep(list( rep(list(numeric(max(dRec$Subject))), each=2)), each=3)
# to use for the cross-tabulation: create lists of repeated variable patterns that match the scores
Truthfulness = data.frame(rep(c('False', 'True'),times=3, each=258))
Theme = data.frame(rep(c('Ecology', 'Ecology', 'Democracy', 'Democracy', 'Social justice', 'Social justice'),each=258))
Truthfulness_fat = data.frame(rep(c('False', 'True'), times=6, each=258))
Theme_fat = data.frame(rep( rep(c('Ecology', 'Democracy', 'Social justice'), each=2), times=2, each=258))
Reception_fat = data.frame(rep( rep(c('No reception', 'Reception'), each=6), times=1, each=258))
success = conds_list
for (i in 1:length(success)) {
for (j in 1:length(success[[i]])) {
for (subj in 1:length(success[[i]][[j]])) {
success[[i]][[j]][subj] = sum(dRec$Success[dRec$Subject == subj &
dRec$Truthfulness == (j - 1) &
dRec$Theme == themes[i]]) / (N_TRIALS/N_CONDS)
}
}
}
success.df = data.frame(unlist(success))
success.df[is.na(success.df)] <- 0
success.df = cbind(success.df,Theme,Truthfulness)
colnames(success.df) = c('Success','Theme','Truthfulness')
xtab1 = ddply(success.df, .(Theme,Truthfulness), summarise, mean = mean(Success), sd = sd(Success))
xtab1$mean = xtab1$mean*100
xtab1$sd = xtab1$sd*100
judgment = conds_list
for (i in 1:length(judgment)) {
for (j in 1:length(judgment[[i]])) {
for (subj in 1:length(judgment[[i]][[j]])) {
judgment[[i]][[j]][subj] = sum(dRec$Judgment[dRec$Subject == subj &
dRec$Truthfulness == (j - 1) &
dRec$Theme == themes[i]]) / (N_TRIALS/N_CONDS)
}
}
}
judgment.df = data.frame(unlist(judgment))
judgment.df[is.na(judgment.df)] <- 0
judgment.df = cbind(judgment.df,Theme,Truthfulness)
colnames(judgment.df) = c('Judgment','Theme','Truthfulness')
xtab2 = ddply(judgment.df, .(Theme,Truthfulness), summarise, mean = mean(Judgment), sd = sd(Judgment))
xtab2$mean = xtab2$mean*100
xtab2$sd = xtab2$sd*100
confidence = conds_list
for (i in 1:length(confidence)) {
for (j in 1:length(confidence[[i]])) {
for (subj in 1:length(confidence[[i]][[j]])) {
confidence[[i]][[j]][subj] = mean(dRec$Confidence[dRec$Subject == subj &
dRec$Truthfulness == (j - 1) &
dRec$Theme == themes[i]])
}
}
}
confidence.df = data.frame(unlist(confidence))
confidence.df[is.na(confidence.df)] <- 0
confidence.df = cbind(confidence.df,Theme,Truthfulness)
colnames(confidence.df) = c('Confidence','Theme','Truthfulness')
xtab3 = ddply(confidence.df, .(Theme,Truthfulness), summarise, mean = mean(Confidence), sd = sd(Confidence))
reception = conds_list
for (i in 1:length(reception)) {
for (j in 1:length(reception[[i]])) {
for (subj in 1:length(reception[[i]][[j]])) {
reception[[i]][[j]][subj] = sum(dRec$Reception[dRec$Subject == subj &
dRec$Truthfulness == (j - 1) &
dRec$Theme == themes[i]]) / (N_TRIALS/N_CONDS)
}
}
}
reception.df = data.frame(unlist(reception))
reception.df[is.na(reception.df)] <- 0
reception.df = cbind(reception.df,Theme,Truthfulness)
colnames(reception.df) = c('Reception','Theme','Truthfulness')
xtab4 = ddply(reception.df, .(Theme,Truthfulness), summarise, mean = mean(Reception), sd = sd(Reception))
xtab4$mean = xtab4$mean*100
xtab4$sd = xtab4$sd*100
WTP = list(conds_list, conds_list)
for (rec_choice in 1:length(WTP)){
for (i in 1:length(WTP[[rec_choice]])) {
for (j in 1:length(WTP[[rec_choice]] [[i]])) {
for (subj in 1:length(WTP[[rec_choice]] [[i]][[j]])) {
WTP[[rec_choice]] [[i]][[j]][subj] = mean(dRec$WTP[dRec$Subject == subj &
dRec$Truthfulness == (j - 1) &
dRec$Theme == themes[i] &
dRec$Reception == (rec_choice - 1) ])}
}
}
}
WTP.df = data.frame(unlist(WTP))
WTP.df = cbind(WTP.df,Theme_fat, Truthfulness_fat, Reception_fat)
colnames(WTP.df) = c('WTP', 'Theme', 'Truthfulness', 'Reception')
xtab5 = ddply(WTP.df, .(Reception,Theme,Truthfulness), summarise, mean = mean(WTP,na.rm=TRUE), sd = sd(WTP,na.rm=TRUE))
year_2020 = numeric(max(dRec$Subject[dRec$Year == 2020]))
year_2021 = numeric(max(dRec$Subject[dRec$Year == 2021]) - length(year_2020))
for (i in 1:length(year_2020)) {
year_2020[i] <- mean(dRec$Estimation_RT[dRec$Subject == i & dRec$Year == 2020])
}
j=1
for (i in min(dRec$Subject[dRec$Year == 2021]):max(dRec$Subject[dRec$Year == 2021])) {
year_2021[j] <- mean(dRec$Estimation_RT[dRec$Subject == i])
j=j+1
}
waves_test = wilcox.test(year_2020,year_2021)
response_successes = array()
for (sub in unique(dRec$Subject)){
response_successes[sub] = sum(dRec$Success[dRec$Subject==sub])
end
}
r = rbinom(258, size=48, prob=0.5)/48*100
sample1 <- data.frame(sample = 'empiric data', values = response_successes/48*100)
sample2 <- data.frame(sample = 'simulated data', values = r)
samples <- rbind(sample1,sample2)
ggplot(samples,aes(x = values, col = sample, fill = sample, group = sample)) + geom_density(alpha=0.2)
success_performances = boot.t.test(x=(response_successes/48*1008), y=r,  alternative = "two.sided", mu=0, paired=FALSE, var.equal=FALSE,
conf.level=0.95, R=100000)
success_performances
r
response_successes
rbinom(258, size=48, prob=0.5)/48*100
rbinom(258, size=48, prob=0.5)
response_successes
success_performances = boot.t.test(x=(response_successes/48*100), y=r,  alternative = "two.sided", mu=0, paired=FALSE, var.equal=FALSE,
conf.level=0.95, R=100000)
success_performances
r
response_successes/48*100
# We will model our distribution via a logistic function.
# We choose a scaling parameter by visualizing the distributions:
# The distribution sd is 3.2;
# create a sequence of x values from 18 to 30, which is near +/- 2sd
x <- seq(18,30, by=0.02)
px<-dlogis(x,24,1.5) # We compute the Logistic pdf for each x with a scale of 1.5
plot(x,px,type="l",xlim=c(18,30),ylim=c(0,max(px)), lwd=3, col="darkred",ylab="f(x)",
main=expression(paste("PDF of Logis(",mu,"=24, ",lambda,"=.5)"))) # Plot
abline(v=c(24),lty=2,col="gray")
# With a 'medium' scale parameter at .5
samples1 = proportionBF(y = response_successes, N = as.integer(rep(48, each=258)),
p = 0.5, iterations=10000, rscale=.5)
1/samples1
chains1 = posterior(samples1, iterations = 10000)
plot(chains1[,"p"], main = "Posterior of true probability\nof 'random-equivalent' behavior")
# the proportion of samples inside the ROPE [0.48 0.52] is 84.99% :
proportionBF1_table = describe_posterior(samples1, centrality="median", dispersion=TRUE,
rope_range=c(0.48, 0.52))
# the proportion of posterior samples inside the ROPE [0.49 0.53] is 100% :
proportionBF1_table2 = describe_posterior(samples1, centrality="median", dispersion=TRUE,
rope_range=c(0.49, 0.53))
# With a wider scale parameter, at 1.5
samples2 = proportionBF(y = response_successes, N = as.integer(rep(48, each=258)),
p = 0.5, iterations=10000, rscale=1.5)
1/samples2
chains2 = posterior(samples2, iterations = 10000)
plot(chains2[,"p"], main = "Posterior of true probability\nof 'random-equivalent' behavior")
# the proportion of samples inside the ROPE [0.48 0.52] is 85.05%
proportionBF2_table = describe_posterior(samples2, centrality="median", dispersion=TRUE,
rope_range=c(0.48, 0.52))
# the proportion of posterior samples inside the ROPE [0.49 0.53] is 100%
proportionBF2_table2 = describe_posterior(samples2, centrality="median", dispersion=TRUE,
rope_range=c(0.49, 0.53))
save.image(paste(project_root, "/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData",sep=""))
load(paste(project_root, "/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", sep=""))
rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memory and report the memory usage
list.of.packages <- c("MKinfer", "ggplot2", "plyr", "BayesFactor", "bayestestR",
"rprojroot")
{
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
lapply(list.of.packages, require, character.only = TRUE)
}
project_root = find_rstudio_root_file()
knitr::opts_knit$set(root.dir = paste(project_root,"/documents/reports", sep=""))
load(paste(project_root, "/outputs/R_environments/ReceivingNews-behavioral_measures_env.RData", sep=""))
pander::pander(xtab1, caption = "Performances (%) in correctly estimating truthfulness, classified by Theme and Truthfulness", digits=4, style='multiline', justify='right')
pander::pander(xtab2, caption = "Proportion (%) of news judged as true, classified by Theme and Truthfulness", digits=4, style='multiline', justify='right')
pander::pander(xtab3, caption = "Confidence in truthfulness estimation, classified by Theme and Truthfulness", digits=4, style='multiline', justify='right')
pander::pander(xtab4, caption = "Choices (%) to receive extra information, classified by Theme and Truthfulness", digits=4, style='multiline', justify='right')
pander::pander(xtab5, caption = "Willingness-To-Pay (from 0 to 25 ECU) to receive or not extra information, classified by Reception choice, Theme and Truthfulness", digits=3, style='multiline', justify='right')
waves_test
ggplot(samples,aes(x = values, col = sample, fill = sample, group = sample)) + geom_density(alpha=0.2)
success_performances
plot(chains1[,"p"], main = "Posterior of true probability\nof 'random-equivalent' behavior")
1/samples1
proportionBF1_table2
plot(chains2[,"p"], main = "Posterior of true probability\nof 'random-equivalent' behavior")
1/samples2
proportionBF2_table2
