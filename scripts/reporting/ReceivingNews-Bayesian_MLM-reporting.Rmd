---
title: "Receiving news - Bayesian Mixed Linear Models"
editor_options:
  markdown:
    wrap: 72
output:
  html_document:
    df_print: paged
---

```         
By Valentin Guigon
July 2023
```


```{r, setup, include = FALSE, results = 'hide'}

# ignore messages and warnings in the document
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
knitr::opts_chunk$set(fig.width = 6, fig.height = 4)

rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.
gc() #free up memory and report the memory usage


# install.packages("devtools")
# devtools::install_github("rmcelreath/rethinking")
# devtools::install_version("BEST", version = "0.5.4", repos = "http://cran.us.r-project.org")

list.of.packages <- c("devtools"
                      , "brms", "rstan", "rjags", "mcmc", "StanHeaders"
                      , "tidyverse", "modelr", "ks", "bayestestR", "logspline"
                      , "emmeans"
                      , "rprojroot"
                      , "tidybayes", "bayesplot", "ggplot2", "see", "GGally"
                      , "ggokabeito", "ggthemes"
                      , "dplyr"
                      , "rethinking", "bayestestR") 
{
  new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
  if(length(new.packages)) install.packages(new.packages)
  lapply(list.of.packages, require, character.only = TRUE)
}

project_root = find_rstudio_root_file()
knitr::opts_knit$set(root.dir = paste(project_root,"/outputs/reports", sep=""))

load(paste(project_root, "/R_environments/ReceivingNews-Bayesian_Mixed_Linear_Models_env.RData", sep=""))

figure_path = (paste(project_root, "/outputs/figures/R", sep=""))

```


# Models

We compute Bayesian Mixed Linear Models (MLM) for our main hypothesis on participants' performances in estimating veracity, as well as alternative models. Computations use 4 mcmc chains, 4000 iterations each plus 1500 warmup iterations each. We use weakly informative priors with 
mu[0,1] and sigma[0,1], except for the non-informative beta response model.

First, we computed a non-informative beta response model to model randomness 
(Jeffrey priors, α = 0.5, β = 0.5):
```{r, echo=FALSE}
formula(mSuccessRandom)
```

Then, we computed a subject random-effect model:
```{r, echo=FALSE}
formula(mSuccessSubject)
```

We computed a cognitive reflection model:
```{r, echo=FALSE}
formula(mSuccessRT)
```

We computed the veracity judgment model:
```{r, echo=FALSE}
formula(mSuccessJudgment)
```

We computed the model corresponding to our hypothesis, the news content imprecision model:
```{r, echo=FALSE}
formula(mSuccessImprecision)
```


We computed the model corresponding to our hypothesis, the news content Polarization model:
```{r, echo=FALSE}
formula(mSuccessPolarization)
```


We computed the model corresponding to our hypothesis, the news content imprecision & Polarization model:
```{r, echo=FALSE}
formula(mSuccessImprecPolar)
```


We computed the model of stickiness of prior knowledge:
```{r, echo=FALSE}
formula(mSuccessOrganization)
```


Finally, we computed the relationship between confidence and success:
```{r, echo=FALSE}
formula(mSuccessConfidence)
```





# Relationship confidence - accuracy (success)

We represented the relationship confidence - accuracy with a model of success as explained by the intercept, the confidence and individual-level intercepts (random effect). The Confidence predictor was standardized and we used the weakly informative priors.

The Bayesian analysis provides strong evidence for the absence of a meaningful relationship between Confidence and Success. The model summary indicates a small positive coefficient for Confidence (β = 0.05, 95% CI [0.02, 0.09]). However, further analysis reveals this effect to be practically insignificant.

The Bayesian R² indicates that Confidence explains only about 0.12% of the variance in Success, suggesting a negligible effect size:

``` {r, echo=FALSE}
Confidence_bayesR2
```

100% of the posterior distribution for the Confidence coefficient falls within the [-0.1, 0.1] ROPE, providing strong evidence that the effect, while non-zero, is practically equivalent to no effect:

``` {r, echo=FALSE}
rope_confidence
```

The interval null Bayes Factor provides extreme evidence against a meaningful effect of Confidence on Success, strongly favoring the null hypothesis of no effect within the [-0.1, 0.1] interval:

``` {r, echo=FALSE}
parameters_bf_interval_interpret[1]
```

The support interval for Confidence [0.00, 0.10] further corroborates the finding of a negligible effect, as it barely excludes zero and is entirely contained within the ROPE:

``` {r, echo=FALSE}
Confidence_si
plot(Confidence_si)

bmp(file=paste(project_root, "/outputs/figures/R/Confidence_effect_Support_Interval.bmp", sep=""),
    width=550, height=350)
plot_Confidence_si = plot(Confidence_si)
plot_Confidence_si
dev.off()
```





# Models comparison

The Bayesian Mixed Linear Model that explains best participants' performances is the model of news content imprecision & Polarization with both variables interacting with news veracity.

``` {r, echo=FALSE}
left_join(model_comparison_table_Success, weights_Success, by = "model")
```


For a summary of the winner model, the imprecision model, please check the following
summary table:

```{r, echo=FALSE}
summary(mSuccessImprecPolar)  # marginal means in odds ratio
```





# Winning model: Posterior estimated effects

We ran a second version of the model, with controls such as the NHST imprecision model:
```{r, echo=FALSE, warning=FALSE}
summary(mSuccessImprecPolar_controlled) 
```

The estimated effects clearly show that prediction success was more likely for true news 
when their content imprecision was at its minimum rather than maximum. 
It was more likely for false news when imprecision was at its maximum rather than minimum:

```{r, echo=FALSE, results='hide'}
mod = mSuccessImprecPolar_controlled
plot_ImprecPolar_MLM_controlled_effect = plot(conditional_effects(mod), ask="FALSE")
```

```{r, echo=FALSE, results='hide', message=FALSE}

bmp(file=paste(project_root, "/outputs/figures/R/Imprecision_Bayes_MLM_ctrl_effect.bmp", sep=""),
    width=550, height=350)
plot_Imprec_MLM_controlled_effect = plot(conditional_effects(mod), ask="FALSE")
plot_Imprec_MLM_controlled_effect$`Imprecision:Veracity`+ 
     scale_color_manual(values = c("#00AFBB","#FC4E07")) + 
     scale_fill_manual(values = c("#00AFBB","#FC4E07"))
dev.off()
```

```{r, echo=FALSE, results='hide'}

bmp(file=paste(project_root, "/outputs/figures/R/Polarization_Bayes_MLM_ctrl_effect.bmp", sep=""),
    width=550, height=350)
plot_Polar_MLM_controlled_effect = plot(conditional_effects(mod), ask="FALSE")
plot_Polar_MLM_controlled_effect$`Polarization:Veracity`+ 
     scale_color_manual(values = c("#00AFBB","#FC4E07")) + 
     scale_fill_manual(values = c("#00AFBB","#FC4E07"))
dev.off()
```


We replot the interaction plot with better suiting colors:

```{r, echo=FALSE, results='hide'}

plot_Imprec_MLM_controlled_effect$`Imprecision:Veracity`+ 
     scale_color_manual(values = c("#00AFBB","#FC4E07")) + 
     scale_fill_manual(values = c("#00AFBB","#FC4E07"))
```

```{r, echo=FALSE, results='hide'}

plot_Polar_MLM_controlled_effect$`Polarization:Veracity`+ 
     scale_color_manual(values = c("#00AFBB","#FC4E07")) + 
     scale_fill_manual(values = c("#00AFBB","#FC4E07"))
```


```{r, fixed-effects draws, include=FALSE}

# compute the trends from the rescaled ctrl model 

ame_ImprecPolar_controlled_draws = mSuccessImprecPolar_controlled %>% 
    emtrends(~ Imprecision + Veracity + Polarization,
             var = "Imprecision",
             at = list(Veracity = levels(mSuccessImprecPolar_controlled$data$Veracity)
                       , Imprecision = c(0, 0.25, 0.5, 0.75)
                       , Polarization = c(0, 0.25, 0.5, 0.75)
                       # , Imprecision = round(quantile(mSuccessImprecision_controlled$data$Imprecision, probs = c(0, 0.25, 0.5, 0.75)), 2)
                       )
             , epred = TRUE, re_formula = NA) %>%
    gather_emmeans_draws %>% 
  mutate(.value = .value / 10) # Scale this down
```

```{r, fixed-effects imprec plot, include=FALSE}

# min. imprecision ~ 2.82; max. imprecision ~ 8.4
ame_Imprec_controlled_plot = ggplot(ame_ImprecPolar_controlled_draws,
       aes(x = .value, fill = factor(Imprecision))) +
    stat_halfeye(slab_alpha = 0.75) +
    scale_fill_okabe_ito(order = c(5, 3, 4, 6)) +
    labs(x = "Average marginal effect on success in estimating veracity of a\n0.1-point increase in the news content imprecision",
         y = "Density", fill = "Imprecision") +
    facet_wrap(vars(Veracity)) +
    theme_clean() + 
    theme(legend.position = "bottom") +
    # to remove border during the print
    theme(panel.background = element_blank(),
    plot.background = element_blank(),
    legend.background = element_rect(fill = 'transparent'),
    panel.border = element_blank())

ame_Imprec_controlled_plot

ggsave("Imprecision_Bayes_MLM_ctrl_rescaled_effect.bmp", path = figure_path, width = 5.5, height = 3.5, device='bmp', dpi=300, limitsize=FALSE)

# plot doesn't show up inline, don't know why

```

```{r, fixed-effects polar plot, include=FALSE}

# min. imprecision ~ 2.82; max. imprecision ~ 8.4
ame_Polar_controlled_plot = ggplot(ame_ImprecPolar_controlled_draws,
       aes(x = .value, fill = factor(Polarization))) +
    stat_halfeye(slab_alpha = 0.75) +
    scale_fill_okabe_ito(order = c(5, 3, 4, 6)) +
    labs(x = "Average marginal effect on success in estimating veracity of a\n0.1-point increase in the news content Polarization",
         y = "Density", fill = "Polarization") +
    facet_wrap(vars(Veracity)) +
    theme_clean() + 
    theme(legend.position = "bottom") +
    # to remove border during the print
    theme(panel.background = element_blank(),
    plot.background = element_blank(),
    legend.background = element_rect(fill = 'transparent'),
    panel.border = element_blank())

ame_Polar_controlled_plot

ggsave("Polarization_Bayes_MLM_ctrl_rescaled_effect.bmp", path = figure_path, width = 5.5, height = 3.5, device='bmp', dpi=300, limitsize=FALSE)

# plot doesn't show up inline, don't know why

```





# Winning model: Prior priors

```{r, preparing-best-model-investigation, include=FALSE}

mod = mSuccessImprecPolar
prior <- prior_samples(mod)
post <- posterior_samples(mod)

```

The priors of the winning model are distributed around p = 0.5:

```{r, echo=FALSE, results='hide'}

prior_draws(mod) %>%
  mutate(p = brms::inv_logit_scaled(Intercept) ) %>%
  ggplot(aes(x = p) ) +  geom_density(fill = "steelblue", adjust = 0.1)

bmp(file=paste(project_root, "/outputs/figures/R/Imprecision_Bayes_MLM_prior.bmp", sep=""),
    width=550, height=350)
prior_draws(mod) %>%
  mutate(p = brms::inv_logit_scaled(Intercept) ) %>%
  ggplot(aes(x = p) ) +  geom_density(fill = "steelblue", adjust = 0.1)
dev.off()
```





# Winning model: Posterior priors

The distribution of the priors in our posterior takes mu~0.1 and sigma~0.1:

```{r, echo=FALSE, results = 'hide'}
H.scv <- Hscv(post[, 1:2])
fhat_post <- kde(x = post[, 1:2], H = H.scv, compute.cont = TRUE)

plot(fhat_post, display = "persp", col = "purple", border = NA,
     xlab = "\nmu", ylab = "\nsigma", zlab = "\np(mu, sigma)",
     shade = 0.8, phi = 30, ticktype = "detailed",
     cex.lab = 1.2, family = "Helvetica")
```





# Winning model: Diagnostics

We check the convergence of the model by looking directly at the chains. The 4 chains overlap
for the 3 GLM parameters and variation is contained:

```{r, echo=FALSE, results = 'hide'}

convergence_plot = mod %>% 
  plot(pars = "^b_", combo = c("dens_overlay", "trace"), widths = c(1, 1.5), theme = theme_bw(base_size = 9, base_family = "Open Sans")  )


bmp(file=paste(project_root, "/outputs/figures/R/Imprecision_Bayes_MLM_convergence.bmp", sep=""),
    width=550, height=350)
mod %>% 
  plot(pars = "^b_", combo = c("dens_overlay", "trace"), widths = c(1, 1.5), theme = theme_bw(base_size = 14, base_family = "Open Sans")  )
dev.off()

convergence_plot = mod %>% plot(pars = "^b_", theme = theme_bw(base_size = 11, base_family = "Open Sans"), widths = c(1, 1.1))

ggsave("Imprecision_Bayes_MLM_convergence.png", plot = convergence_plot[[1]], path = figure_path, width = 6, height = 4.5, device='png', dpi=300, limitsize=FALSE)

```
  

Moreover, the posterior probabilities closely map *y*, the observed data:

```{r, echo=FALSE, results = 'hide'}
pp_check(mod, nsamples = 1e2)

bmp(file=paste(project_root, "/outputs/figures/R/Imprecision_Bayes_MLM_mapping.bmp", sep=""),
    width=1100, height=700)
pp_check(mod, nsamples = 1e2)
dev.off()

```

We check the posterior samples, by looking at the Autocorrelation for each parameter.
Positive autocorrelation means the chain tends to stay in the same area between iterations.
Ideally, we want it to drop quickly to zero with increasing lag.

The posterior samples for False news and True news look uncorrelated after two lags on the graph:

```{r, echo=FALSE, results = 'hide'}

post <- posterior_samples(mod, add_chain = TRUE)
plot_False = post %>% mcmc_acf(pars = vars(`b_VeracityFalse:Imprecision`), lags = 10)
plot_True = post %>% mcmc_acf(pars = vars(`b_VeracityTrue:Imprecision`), lags = 10)
 
bayesplot_theme_update(text = element_text(size = 11, family = "sans"))

autocorrelation_plot = bayesplot_grid(
    plot_False, plot_True,
    grid_args = list(ncol = 2),
    subtitles = c("False news", 
                  "True news")
)

bmp(file=paste(project_root, "/outputs/figures/R/Imprecision_Bayes_MLM_autocorrelation.bmp", sep=""),
    width=1100, height=700)
bayesplot_grid(plot_False, plot_True, grid_args = list(ncol = 2), subtitles = c("False news", "True news"))
dev.off()

autocorrelation_plot

ggsave("Imprecision_Bayes_MLM_autocorrelation.png", plot = autocorrelation_plot, path = figure_path, width = 5.5, height = 3.5, device='png', dpi=300, limitsize=FALSE)


```

